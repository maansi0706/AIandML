{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Statement\n",
    "The problem that we are going to solve here is that given a set of features that describe a tumour whether it is Malignant or Benign, our machine learning model must predict whether the tumour is Malignant or Benign. To train our machine learning model with tumour data, we will be using Small Cell Lung Cancer dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87139402</td>\n",
       "      <td>B</td>\n",
       "      <td>12.32</td>\n",
       "      <td>12.39</td>\n",
       "      <td>78.85</td>\n",
       "      <td>464.1</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.06981</td>\n",
       "      <td>0.03987</td>\n",
       "      <td>0.03700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>15.64</td>\n",
       "      <td>86.97</td>\n",
       "      <td>549.1</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.09391</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.06771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8910251</td>\n",
       "      <td>B</td>\n",
       "      <td>10.60</td>\n",
       "      <td>18.95</td>\n",
       "      <td>69.28</td>\n",
       "      <td>346.4</td>\n",
       "      <td>0.09688</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.06387</td>\n",
       "      <td>0.02642</td>\n",
       "      <td>...</td>\n",
       "      <td>11.88</td>\n",
       "      <td>22.94</td>\n",
       "      <td>78.28</td>\n",
       "      <td>424.8</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.19160</td>\n",
       "      <td>0.07926</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.07587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>905520</td>\n",
       "      <td>B</td>\n",
       "      <td>11.04</td>\n",
       "      <td>16.83</td>\n",
       "      <td>70.92</td>\n",
       "      <td>373.2</td>\n",
       "      <td>0.10770</td>\n",
       "      <td>0.07804</td>\n",
       "      <td>0.03046</td>\n",
       "      <td>0.02480</td>\n",
       "      <td>...</td>\n",
       "      <td>12.41</td>\n",
       "      <td>26.44</td>\n",
       "      <td>79.93</td>\n",
       "      <td>471.4</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.10670</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>0.07881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>868871</td>\n",
       "      <td>B</td>\n",
       "      <td>11.28</td>\n",
       "      <td>13.39</td>\n",
       "      <td>73.00</td>\n",
       "      <td>384.8</td>\n",
       "      <td>0.11640</td>\n",
       "      <td>0.11360</td>\n",
       "      <td>0.04635</td>\n",
       "      <td>0.04796</td>\n",
       "      <td>...</td>\n",
       "      <td>11.92</td>\n",
       "      <td>15.77</td>\n",
       "      <td>76.53</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.08669</td>\n",
       "      <td>0.08611</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.06784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9012568</td>\n",
       "      <td>B</td>\n",
       "      <td>15.19</td>\n",
       "      <td>13.21</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.8</td>\n",
       "      <td>0.07963</td>\n",
       "      <td>0.06934</td>\n",
       "      <td>0.03393</td>\n",
       "      <td>0.02657</td>\n",
       "      <td>...</td>\n",
       "      <td>16.20</td>\n",
       "      <td>15.73</td>\n",
       "      <td>104.50</td>\n",
       "      <td>819.1</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.13620</td>\n",
       "      <td>0.08178</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.06766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0  87139402         B        12.32         12.39           78.85      464.1   \n",
       "1   8910251         B        10.60         18.95           69.28      346.4   \n",
       "2    905520         B        11.04         16.83           70.92      373.2   \n",
       "3    868871         B        11.28         13.39           73.00      384.8   \n",
       "4   9012568         B        15.19         13.21           97.65      711.8   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  points_mean  ...  \\\n",
       "0          0.10280           0.06981         0.03987      0.03700  ...   \n",
       "1          0.09688           0.11470         0.06387      0.02642  ...   \n",
       "2          0.10770           0.07804         0.03046      0.02480  ...   \n",
       "3          0.11640           0.11360         0.04635      0.04796  ...   \n",
       "4          0.07963           0.06934         0.03393      0.02657  ...   \n",
       "\n",
       "   radius_worst  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0         13.50          15.64            86.97       549.1            0.1385   \n",
       "1         11.88          22.94            78.28       424.8            0.1213   \n",
       "2         12.41          26.44            79.93       471.4            0.1369   \n",
       "3         11.92          15.77            76.53       434.0            0.1367   \n",
       "4         16.20          15.73           104.50       819.1            0.1126   \n",
       "\n",
       "   compactness_worst  concavity_worst  points_worst  symmetry_worst  \\\n",
       "0             0.1266          0.12420       0.09391          0.2827   \n",
       "1             0.2515          0.19160       0.07926          0.2940   \n",
       "2             0.1482          0.10670       0.07431          0.2998   \n",
       "3             0.1822          0.08669       0.08611          0.2102   \n",
       "4             0.1737          0.13620       0.08178          0.2487   \n",
       "\n",
       "   dimension_worst  \n",
       "0          0.06771  \n",
       "1          0.07587  \n",
       "2          0.07881  \n",
       "3          0.06784  \n",
       "4          0.06766  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/Mounika-Kajjam/Datasets/master/wbcd.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for frequency of B and M\n",
    "data.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "diagnosis            0\n",
       "radius_mean          0\n",
       "texture_mean         0\n",
       "perimeter_mean       0\n",
       "area_mean            0\n",
       "smoothness_mean      0\n",
       "compactness_mean     0\n",
       "concavity_mean       0\n",
       "points_mean          0\n",
       "symmetry_mean        0\n",
       "dimension_mean       0\n",
       "radius_se            0\n",
       "texture_se           0\n",
       "perimeter_se         0\n",
       "area_se              0\n",
       "smoothness_se        0\n",
       "compactness_se       0\n",
       "concavity_se         0\n",
       "points_se            0\n",
       "symmetry_se          0\n",
       "dimension_se         0\n",
       "radius_worst         0\n",
       "texture_worst        0\n",
       "perimeter_worst      0\n",
       "area_worst           0\n",
       "smoothness_worst     0\n",
       "compactness_worst    0\n",
       "concavity_worst      0\n",
       "points_worst         0\n",
       "symmetry_worst       0\n",
       "dimension_worst      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into input and output--> Train and test\n",
    "# Train--> Building the model\n",
    "# Test--> How well the model has learnt(Generaize on unseen data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.32</td>\n",
       "      <td>12.39</td>\n",
       "      <td>78.85</td>\n",
       "      <td>464.1</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.06981</td>\n",
       "      <td>0.03987</td>\n",
       "      <td>0.03700</td>\n",
       "      <td>0.1959</td>\n",
       "      <td>0.05955</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>15.64</td>\n",
       "      <td>86.97</td>\n",
       "      <td>549.1</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.09391</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.06771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.60</td>\n",
       "      <td>18.95</td>\n",
       "      <td>69.28</td>\n",
       "      <td>346.4</td>\n",
       "      <td>0.09688</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.06387</td>\n",
       "      <td>0.02642</td>\n",
       "      <td>0.1922</td>\n",
       "      <td>0.06491</td>\n",
       "      <td>...</td>\n",
       "      <td>11.88</td>\n",
       "      <td>22.94</td>\n",
       "      <td>78.28</td>\n",
       "      <td>424.8</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.19160</td>\n",
       "      <td>0.07926</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.07587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.04</td>\n",
       "      <td>16.83</td>\n",
       "      <td>70.92</td>\n",
       "      <td>373.2</td>\n",
       "      <td>0.10770</td>\n",
       "      <td>0.07804</td>\n",
       "      <td>0.03046</td>\n",
       "      <td>0.02480</td>\n",
       "      <td>0.1714</td>\n",
       "      <td>0.06340</td>\n",
       "      <td>...</td>\n",
       "      <td>12.41</td>\n",
       "      <td>26.44</td>\n",
       "      <td>79.93</td>\n",
       "      <td>471.4</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.10670</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>0.07881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.28</td>\n",
       "      <td>13.39</td>\n",
       "      <td>73.00</td>\n",
       "      <td>384.8</td>\n",
       "      <td>0.11640</td>\n",
       "      <td>0.11360</td>\n",
       "      <td>0.04635</td>\n",
       "      <td>0.04796</td>\n",
       "      <td>0.1771</td>\n",
       "      <td>0.06072</td>\n",
       "      <td>...</td>\n",
       "      <td>11.92</td>\n",
       "      <td>15.77</td>\n",
       "      <td>76.53</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.08669</td>\n",
       "      <td>0.08611</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.06784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.19</td>\n",
       "      <td>13.21</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.8</td>\n",
       "      <td>0.07963</td>\n",
       "      <td>0.06934</td>\n",
       "      <td>0.03393</td>\n",
       "      <td>0.02657</td>\n",
       "      <td>0.1721</td>\n",
       "      <td>0.05544</td>\n",
       "      <td>...</td>\n",
       "      <td>16.20</td>\n",
       "      <td>15.73</td>\n",
       "      <td>104.50</td>\n",
       "      <td>819.1</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.13620</td>\n",
       "      <td>0.08178</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.06766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        12.32         12.39           78.85      464.1          0.10280   \n",
       "1        10.60         18.95           69.28      346.4          0.09688   \n",
       "2        11.04         16.83           70.92      373.2          0.10770   \n",
       "3        11.28         13.39           73.00      384.8          0.11640   \n",
       "4        15.19         13.21           97.65      711.8          0.07963   \n",
       "\n",
       "   compactness_mean  concavity_mean  points_mean  symmetry_mean  \\\n",
       "0           0.06981         0.03987      0.03700         0.1959   \n",
       "1           0.11470         0.06387      0.02642         0.1922   \n",
       "2           0.07804         0.03046      0.02480         0.1714   \n",
       "3           0.11360         0.04635      0.04796         0.1771   \n",
       "4           0.06934         0.03393      0.02657         0.1721   \n",
       "\n",
       "   dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.05955  ...         13.50          15.64            86.97   \n",
       "1         0.06491  ...         11.88          22.94            78.28   \n",
       "2         0.06340  ...         12.41          26.44            79.93   \n",
       "3         0.06072  ...         11.92          15.77            76.53   \n",
       "4         0.05544  ...         16.20          15.73           104.50   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0       549.1            0.1385             0.1266          0.12420   \n",
       "1       424.8            0.1213             0.2515          0.19160   \n",
       "2       471.4            0.1369             0.1482          0.10670   \n",
       "3       434.0            0.1367             0.1822          0.08669   \n",
       "4       819.1            0.1126             0.1737          0.13620   \n",
       "\n",
       "   points_worst  symmetry_worst  dimension_worst  \n",
       "0       0.09391          0.2827          0.06771  \n",
       "1       0.07926          0.2940          0.07587  \n",
       "2       0.07431          0.2998          0.07881  \n",
       "3       0.08611          0.2102          0.06784  \n",
       "4       0.08178          0.2487          0.06766  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing Input and Output\n",
    "# Drop the id and diagnosis columns\n",
    "X = data.drop(['id', 'diagnosis'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    B\n",
       "1    B\n",
       "2    B\n",
       "3    B\n",
       "4    B\n",
       "Name: diagnosis, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing Output Column\n",
    "y = data.diagnosis\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing Training and Testing Data\n",
    "# Storing 70% of the data(569 rows) into training and remaining 30% of the data into testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, \n",
    "                                                    random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 30)\n",
      "(171, 30)\n",
      "(398,)\n",
      "(171,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>18.310</td>\n",
       "      <td>20.58</td>\n",
       "      <td>120.80</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>0.10680</td>\n",
       "      <td>0.12480</td>\n",
       "      <td>0.15690</td>\n",
       "      <td>0.09451</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.05941</td>\n",
       "      <td>...</td>\n",
       "      <td>21.860</td>\n",
       "      <td>26.20</td>\n",
       "      <td>142.20</td>\n",
       "      <td>1493.0</td>\n",
       "      <td>0.1492</td>\n",
       "      <td>0.2536</td>\n",
       "      <td>0.3759</td>\n",
       "      <td>0.15100</td>\n",
       "      <td>0.3074</td>\n",
       "      <td>0.07863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>16.300</td>\n",
       "      <td>15.70</td>\n",
       "      <td>104.70</td>\n",
       "      <td>819.8</td>\n",
       "      <td>0.09427</td>\n",
       "      <td>0.06712</td>\n",
       "      <td>0.05526</td>\n",
       "      <td>0.04563</td>\n",
       "      <td>0.1711</td>\n",
       "      <td>0.05657</td>\n",
       "      <td>...</td>\n",
       "      <td>17.320</td>\n",
       "      <td>17.76</td>\n",
       "      <td>109.80</td>\n",
       "      <td>928.2</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1361</td>\n",
       "      <td>0.1947</td>\n",
       "      <td>0.13570</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.07230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>13.560</td>\n",
       "      <td>13.90</td>\n",
       "      <td>88.59</td>\n",
       "      <td>561.3</td>\n",
       "      <td>0.10510</td>\n",
       "      <td>0.11920</td>\n",
       "      <td>0.07860</td>\n",
       "      <td>0.04451</td>\n",
       "      <td>0.1962</td>\n",
       "      <td>0.06303</td>\n",
       "      <td>...</td>\n",
       "      <td>14.980</td>\n",
       "      <td>17.13</td>\n",
       "      <td>101.10</td>\n",
       "      <td>686.6</td>\n",
       "      <td>0.1376</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>0.2577</td>\n",
       "      <td>0.09090</td>\n",
       "      <td>0.3065</td>\n",
       "      <td>0.08177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>8.219</td>\n",
       "      <td>20.70</td>\n",
       "      <td>53.27</td>\n",
       "      <td>203.9</td>\n",
       "      <td>0.09405</td>\n",
       "      <td>0.13050</td>\n",
       "      <td>0.13210</td>\n",
       "      <td>0.02168</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.08261</td>\n",
       "      <td>...</td>\n",
       "      <td>9.092</td>\n",
       "      <td>29.72</td>\n",
       "      <td>58.08</td>\n",
       "      <td>249.8</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.4310</td>\n",
       "      <td>0.5381</td>\n",
       "      <td>0.07879</td>\n",
       "      <td>0.3322</td>\n",
       "      <td>0.14860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>13.660</td>\n",
       "      <td>15.15</td>\n",
       "      <td>88.27</td>\n",
       "      <td>580.6</td>\n",
       "      <td>0.08268</td>\n",
       "      <td>0.07548</td>\n",
       "      <td>0.04249</td>\n",
       "      <td>0.02471</td>\n",
       "      <td>0.1792</td>\n",
       "      <td>0.05897</td>\n",
       "      <td>...</td>\n",
       "      <td>14.540</td>\n",
       "      <td>19.64</td>\n",
       "      <td>97.96</td>\n",
       "      <td>657.0</td>\n",
       "      <td>0.1275</td>\n",
       "      <td>0.3104</td>\n",
       "      <td>0.2569</td>\n",
       "      <td>0.10540</td>\n",
       "      <td>0.3387</td>\n",
       "      <td>0.09638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>19.450</td>\n",
       "      <td>19.33</td>\n",
       "      <td>126.50</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>0.10350</td>\n",
       "      <td>0.11880</td>\n",
       "      <td>0.13790</td>\n",
       "      <td>0.08591</td>\n",
       "      <td>0.1776</td>\n",
       "      <td>0.05647</td>\n",
       "      <td>...</td>\n",
       "      <td>25.700</td>\n",
       "      <td>24.57</td>\n",
       "      <td>163.10</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>0.1497</td>\n",
       "      <td>0.3161</td>\n",
       "      <td>0.4317</td>\n",
       "      <td>0.19990</td>\n",
       "      <td>0.3379</td>\n",
       "      <td>0.08950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>12.450</td>\n",
       "      <td>16.41</td>\n",
       "      <td>82.85</td>\n",
       "      <td>476.7</td>\n",
       "      <td>0.09514</td>\n",
       "      <td>0.15110</td>\n",
       "      <td>0.15440</td>\n",
       "      <td>0.04846</td>\n",
       "      <td>0.2082</td>\n",
       "      <td>0.07325</td>\n",
       "      <td>...</td>\n",
       "      <td>13.780</td>\n",
       "      <td>21.03</td>\n",
       "      <td>97.82</td>\n",
       "      <td>580.6</td>\n",
       "      <td>0.1175</td>\n",
       "      <td>0.4061</td>\n",
       "      <td>0.4896</td>\n",
       "      <td>0.13420</td>\n",
       "      <td>0.3231</td>\n",
       "      <td>0.10340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>17.950</td>\n",
       "      <td>20.01</td>\n",
       "      <td>114.20</td>\n",
       "      <td>982.0</td>\n",
       "      <td>0.08402</td>\n",
       "      <td>0.06722</td>\n",
       "      <td>0.07293</td>\n",
       "      <td>0.05596</td>\n",
       "      <td>0.2129</td>\n",
       "      <td>0.05025</td>\n",
       "      <td>...</td>\n",
       "      <td>20.580</td>\n",
       "      <td>27.83</td>\n",
       "      <td>129.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.1072</td>\n",
       "      <td>0.1202</td>\n",
       "      <td>0.2249</td>\n",
       "      <td>0.11850</td>\n",
       "      <td>0.4882</td>\n",
       "      <td>0.06111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>11.460</td>\n",
       "      <td>18.16</td>\n",
       "      <td>73.59</td>\n",
       "      <td>403.1</td>\n",
       "      <td>0.08853</td>\n",
       "      <td>0.07694</td>\n",
       "      <td>0.03344</td>\n",
       "      <td>0.01502</td>\n",
       "      <td>0.1411</td>\n",
       "      <td>0.06243</td>\n",
       "      <td>...</td>\n",
       "      <td>12.680</td>\n",
       "      <td>21.61</td>\n",
       "      <td>82.69</td>\n",
       "      <td>489.8</td>\n",
       "      <td>0.1144</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.1226</td>\n",
       "      <td>0.05509</td>\n",
       "      <td>0.2208</td>\n",
       "      <td>0.07638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>13.000</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.07389</td>\n",
       "      <td>...</td>\n",
       "      <td>15.490</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "431       18.310         20.58          120.80     1052.0          0.10680   \n",
       "389       16.300         15.70          104.70      819.8          0.09427   \n",
       "309       13.560         13.90           88.59      561.3          0.10510   \n",
       "111        8.219         20.70           53.27      203.9          0.09405   \n",
       "35        13.660         15.15           88.27      580.6          0.08268   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "369       19.450         19.33          126.50     1169.0          0.10350   \n",
       "320       12.450         16.41           82.85      476.7          0.09514   \n",
       "527       17.950         20.01          114.20      982.0          0.08402   \n",
       "125       11.460         18.16           73.59      403.1          0.08853   \n",
       "265       13.000         21.82           87.50      519.8          0.12730   \n",
       "\n",
       "     compactness_mean  concavity_mean  points_mean  symmetry_mean  \\\n",
       "431           0.12480         0.15690      0.09451         0.1860   \n",
       "389           0.06712         0.05526      0.04563         0.1711   \n",
       "309           0.11920         0.07860      0.04451         0.1962   \n",
       "111           0.13050         0.13210      0.02168         0.2222   \n",
       "35            0.07548         0.04249      0.02471         0.1792   \n",
       "..                ...             ...          ...            ...   \n",
       "369           0.11880         0.13790      0.08591         0.1776   \n",
       "320           0.15110         0.15440      0.04846         0.2082   \n",
       "527           0.06722         0.07293      0.05596         0.2129   \n",
       "125           0.07694         0.03344      0.01502         0.1411   \n",
       "265           0.19320         0.18590      0.09353         0.2350   \n",
       "\n",
       "     dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "431         0.05941  ...        21.860          26.20           142.20   \n",
       "389         0.05657  ...        17.320          17.76           109.80   \n",
       "309         0.06303  ...        14.980          17.13           101.10   \n",
       "111         0.08261  ...         9.092          29.72            58.08   \n",
       "35          0.05897  ...        14.540          19.64            97.96   \n",
       "..              ...  ...           ...            ...              ...   \n",
       "369         0.05647  ...        25.700          24.57           163.10   \n",
       "320         0.07325  ...        13.780          21.03            97.82   \n",
       "527         0.05025  ...        20.580          27.83           129.20   \n",
       "125         0.06243  ...        12.680          21.61            82.69   \n",
       "265         0.07389  ...        15.490          30.73           106.20   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "431      1493.0            0.1492             0.2536           0.3759   \n",
       "389       928.2            0.1354             0.1361           0.1947   \n",
       "309       686.6            0.1376             0.2698           0.2577   \n",
       "111       249.8            0.1630             0.4310           0.5381   \n",
       "35        657.0            0.1275             0.3104           0.2569   \n",
       "..          ...               ...                ...              ...   \n",
       "369      1972.0            0.1497             0.3161           0.4317   \n",
       "320       580.6            0.1175             0.4061           0.4896   \n",
       "527      1261.0            0.1072             0.1202           0.2249   \n",
       "125       489.8            0.1144             0.1789           0.1226   \n",
       "265       739.3            0.1703             0.5401           0.5390   \n",
       "\n",
       "     points_worst  symmetry_worst  dimension_worst  \n",
       "431       0.15100          0.3074          0.07863  \n",
       "389       0.13570          0.2300          0.07230  \n",
       "309       0.09090          0.3065          0.08177  \n",
       "111       0.07879          0.3322          0.14860  \n",
       "35        0.10540          0.3387          0.09638  \n",
       "..            ...             ...              ...  \n",
       "369       0.19990          0.3379          0.08950  \n",
       "320       0.13420          0.3231          0.10340  \n",
       "527       0.11850          0.4882          0.06111  \n",
       "125       0.05509          0.2208          0.07638  \n",
       "265       0.20600          0.4378          0.10720  \n",
       "\n",
       "[398 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before Splitting if you apply standardization--> you are considering whole\n",
    "# you are including test data also into training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.077524</td>\n",
       "      <td>0.385200</td>\n",
       "      <td>-0.028576</td>\n",
       "      <td>-0.181721</td>\n",
       "      <td>1.617086</td>\n",
       "      <td>1.210962</td>\n",
       "      <td>0.105416</td>\n",
       "      <td>0.353917</td>\n",
       "      <td>1.441699</td>\n",
       "      <td>1.621128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217083</td>\n",
       "      <td>0.452310</td>\n",
       "      <td>0.154687</td>\n",
       "      <td>0.075338</td>\n",
       "      <td>1.470507</td>\n",
       "      <td>0.755583</td>\n",
       "      <td>0.005892</td>\n",
       "      <td>0.674696</td>\n",
       "      <td>0.532371</td>\n",
       "      <td>1.661987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.644210</td>\n",
       "      <td>-0.376307</td>\n",
       "      <td>-0.630196</td>\n",
       "      <td>-0.629478</td>\n",
       "      <td>0.808428</td>\n",
       "      <td>-0.078482</td>\n",
       "      <td>-0.406623</td>\n",
       "      <td>-0.055776</td>\n",
       "      <td>-0.746101</td>\n",
       "      <td>0.554649</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.541540</td>\n",
       "      <td>0.425511</td>\n",
       "      <td>-0.526524</td>\n",
       "      <td>-0.549443</td>\n",
       "      <td>0.146485</td>\n",
       "      <td>-0.400616</td>\n",
       "      <td>-0.607829</td>\n",
       "      <td>-0.159783</td>\n",
       "      <td>-0.649397</td>\n",
       "      <td>-0.331922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.392671</td>\n",
       "      <td>-0.471786</td>\n",
       "      <td>-0.431337</td>\n",
       "      <td>-0.427265</td>\n",
       "      <td>-0.688285</td>\n",
       "      <td>-0.898236</td>\n",
       "      <td>-0.696996</td>\n",
       "      <td>-0.630673</td>\n",
       "      <td>-0.010737</td>\n",
       "      <td>-0.617927</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362539</td>\n",
       "      <td>-0.550999</td>\n",
       "      <td>-0.430883</td>\n",
       "      <td>-0.402265</td>\n",
       "      <td>-0.391807</td>\n",
       "      <td>-0.613767</td>\n",
       "      <td>-0.364118</td>\n",
       "      <td>-0.197839</td>\n",
       "      <td>0.654169</td>\n",
       "      <td>-0.558780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.415801</td>\n",
       "      <td>-0.665074</td>\n",
       "      <td>-0.404851</td>\n",
       "      <td>-0.475219</td>\n",
       "      <td>1.400979</td>\n",
       "      <td>0.139137</td>\n",
       "      <td>-0.325629</td>\n",
       "      <td>-0.363643</td>\n",
       "      <td>0.516091</td>\n",
       "      <td>0.465086</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.526623</td>\n",
       "      <td>-0.676622</td>\n",
       "      <td>-0.583600</td>\n",
       "      <td>-0.549987</td>\n",
       "      <td>1.149269</td>\n",
       "      <td>-0.465763</td>\n",
       "      <td>-0.363183</td>\n",
       "      <td>-0.417921</td>\n",
       "      <td>0.464889</td>\n",
       "      <td>-0.448273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.629754</td>\n",
       "      <td>-0.604526</td>\n",
       "      <td>-0.499866</td>\n",
       "      <td>-0.603191</td>\n",
       "      <td>0.933909</td>\n",
       "      <td>1.316231</td>\n",
       "      <td>1.011138</td>\n",
       "      <td>0.733116</td>\n",
       "      <td>3.205109</td>\n",
       "      <td>1.510897</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.490396</td>\n",
       "      <td>0.157515</td>\n",
       "      <td>-0.421319</td>\n",
       "      <td>-0.478029</td>\n",
       "      <td>0.302763</td>\n",
       "      <td>1.014906</td>\n",
       "      <td>0.860048</td>\n",
       "      <td>1.146956</td>\n",
       "      <td>4.775544</td>\n",
       "      <td>1.019133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>-0.913098</td>\n",
       "      <td>1.172324</td>\n",
       "      <td>-0.924489</td>\n",
       "      <td>-0.806559</td>\n",
       "      <td>-0.960859</td>\n",
       "      <td>-0.673919</td>\n",
       "      <td>-0.874780</td>\n",
       "      <td>-1.016766</td>\n",
       "      <td>0.636823</td>\n",
       "      <td>0.073768</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.641695</td>\n",
       "      <td>1.006726</td>\n",
       "      <td>-0.669060</td>\n",
       "      <td>-0.634088</td>\n",
       "      <td>-0.482969</td>\n",
       "      <td>-0.540397</td>\n",
       "      <td>-0.957069</td>\n",
       "      <td>-1.204563</td>\n",
       "      <td>0.306881</td>\n",
       "      <td>-0.401520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>-1.534429</td>\n",
       "      <td>-1.100553</td>\n",
       "      <td>-1.532835</td>\n",
       "      <td>-1.194808</td>\n",
       "      <td>-0.301385</td>\n",
       "      <td>-1.119109</td>\n",
       "      <td>-1.068863</td>\n",
       "      <td>-1.233148</td>\n",
       "      <td>-0.292443</td>\n",
       "      <td>0.619409</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.444641</td>\n",
       "      <td>-1.406910</td>\n",
       "      <td>-1.457018</td>\n",
       "      <td>-1.080697</td>\n",
       "      <td>-0.665293</td>\n",
       "      <td>-1.126909</td>\n",
       "      <td>-1.246809</td>\n",
       "      <td>-1.703417</td>\n",
       "      <td>-0.461762</td>\n",
       "      <td>-0.283575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>-0.112219</td>\n",
       "      <td>0.620406</td>\n",
       "      <td>-0.156383</td>\n",
       "      <td>-0.230541</td>\n",
       "      <td>-1.125379</td>\n",
       "      <td>-0.356773</td>\n",
       "      <td>-0.558329</td>\n",
       "      <td>-0.665145</td>\n",
       "      <td>-0.610735</td>\n",
       "      <td>-0.572457</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.264515</td>\n",
       "      <td>0.770555</td>\n",
       "      <td>-0.244537</td>\n",
       "      <td>-0.351514</td>\n",
       "      <td>-1.346840</td>\n",
       "      <td>-0.479045</td>\n",
       "      <td>-0.567132</td>\n",
       "      <td>-0.757521</td>\n",
       "      <td>-0.702066</td>\n",
       "      <td>-0.721353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>-0.005242</td>\n",
       "      <td>-0.495074</td>\n",
       "      <td>0.023136</td>\n",
       "      <td>-0.110946</td>\n",
       "      <td>0.968765</td>\n",
       "      <td>0.510448</td>\n",
       "      <td>0.158451</td>\n",
       "      <td>0.157954</td>\n",
       "      <td>0.388043</td>\n",
       "      <td>-0.199052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074308</td>\n",
       "      <td>-0.564399</td>\n",
       "      <td>0.077557</td>\n",
       "      <td>-0.053352</td>\n",
       "      <td>0.854077</td>\n",
       "      <td>0.489936</td>\n",
       "      <td>0.254280</td>\n",
       "      <td>0.396537</td>\n",
       "      <td>0.321694</td>\n",
       "      <td>-0.225665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1.397019</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>1.262111</td>\n",
       "      <td>1.332277</td>\n",
       "      <td>-0.451265</td>\n",
       "      <td>-0.811342</td>\n",
       "      <td>-0.063341</td>\n",
       "      <td>0.316263</td>\n",
       "      <td>-0.921710</td>\n",
       "      <td>-1.761567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835062</td>\n",
       "      <td>-0.190880</td>\n",
       "      <td>0.722362</td>\n",
       "      <td>0.689788</td>\n",
       "      <td>-0.313668</td>\n",
       "      <td>-0.839567</td>\n",
       "      <td>-0.213027</td>\n",
       "      <td>0.274269</td>\n",
       "      <td>-0.502910</td>\n",
       "      <td>-1.405115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0      -0.077524      0.385200       -0.028576  -0.181721         1.617086   \n",
       "1      -0.644210     -0.376307       -0.630196  -0.629478         0.808428   \n",
       "2      -0.392671     -0.471786       -0.431337  -0.427265        -0.688285   \n",
       "3      -0.415801     -0.665074       -0.404851  -0.475219         1.400979   \n",
       "4      -0.629754     -0.604526       -0.499866  -0.603191         0.933909   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "166    -0.913098      1.172324       -0.924489  -0.806559        -0.960859   \n",
       "167    -1.534429     -1.100553       -1.532835  -1.194808        -0.301385   \n",
       "168    -0.112219      0.620406       -0.156383  -0.230541        -1.125379   \n",
       "169    -0.005242     -0.495074        0.023136  -0.110946         0.968765   \n",
       "170     1.397019      0.187255        1.262111   1.332277        -0.451265   \n",
       "\n",
       "     compactness_mean  concavity_mean  points_mean  symmetry_mean  \\\n",
       "0            1.210962        0.105416     0.353917       1.441699   \n",
       "1           -0.078482       -0.406623    -0.055776      -0.746101   \n",
       "2           -0.898236       -0.696996    -0.630673      -0.010737   \n",
       "3            0.139137       -0.325629    -0.363643       0.516091   \n",
       "4            1.316231        1.011138     0.733116       3.205109   \n",
       "..                ...             ...          ...            ...   \n",
       "166         -0.673919       -0.874780    -1.016766       0.636823   \n",
       "167         -1.119109       -1.068863    -1.233148      -0.292443   \n",
       "168         -0.356773       -0.558329    -0.665145      -0.610735   \n",
       "169          0.510448        0.158451     0.157954       0.388043   \n",
       "170         -0.811342       -0.063341     0.316263      -0.921710   \n",
       "\n",
       "     dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0          1.621128  ...      0.217083       0.452310         0.154687   \n",
       "1          0.554649  ...     -0.541540       0.425511        -0.526524   \n",
       "2         -0.617927  ...     -0.362539      -0.550999        -0.430883   \n",
       "3          0.465086  ...     -0.526623      -0.676622        -0.583600   \n",
       "4          1.510897  ...     -0.490396       0.157515        -0.421319   \n",
       "..              ...  ...           ...            ...              ...   \n",
       "166        0.073768  ...     -0.641695       1.006726        -0.669060   \n",
       "167        0.619409  ...     -1.444641      -1.406910        -1.457018   \n",
       "168       -0.572457  ...     -0.264515       0.770555        -0.244537   \n",
       "169       -0.199052  ...      0.074308      -0.564399         0.077557   \n",
       "170       -1.761567  ...      0.835062      -0.190880         0.722362   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      0.075338          1.470507           0.755583         0.005892   \n",
       "1     -0.549443          0.146485          -0.400616        -0.607829   \n",
       "2     -0.402265         -0.391807          -0.613767        -0.364118   \n",
       "3     -0.549987          1.149269          -0.465763        -0.363183   \n",
       "4     -0.478029          0.302763           1.014906         0.860048   \n",
       "..          ...               ...                ...              ...   \n",
       "166   -0.634088         -0.482969          -0.540397        -0.957069   \n",
       "167   -1.080697         -0.665293          -1.126909        -1.246809   \n",
       "168   -0.351514         -1.346840          -0.479045        -0.567132   \n",
       "169   -0.053352          0.854077           0.489936         0.254280   \n",
       "170    0.689788         -0.313668          -0.839567        -0.213027   \n",
       "\n",
       "     points_worst  symmetry_worst  dimension_worst  \n",
       "0        0.674696        0.532371         1.661987  \n",
       "1       -0.159783       -0.649397        -0.331922  \n",
       "2       -0.197839        0.654169        -0.558780  \n",
       "3       -0.417921        0.464889        -0.448273  \n",
       "4        1.146956        4.775544         1.019133  \n",
       "..            ...             ...              ...  \n",
       "166     -1.204563        0.306881        -0.401520  \n",
       "167     -1.703417       -0.461762        -0.283575  \n",
       "168     -0.757521       -0.702066        -0.721353  \n",
       "169      0.396537        0.321694        -0.225665  \n",
       "170      0.274269       -0.502910        -1.405115  \n",
       "\n",
       "[171 rows x 30 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scaling for training data\n",
    "scaled_X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "scaled_X_train\n",
    "\n",
    "#Scaling for test data\n",
    "#Testing the data based on training data\n",
    "scaled_X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "scaled_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=40, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Building:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=40, metric='euclidean')\n",
    "\n",
    "# Apply the knn object on the dataset(Training Phase)\n",
    "# Syntax: objectName.fit(Input, Output)\n",
    "knn.fit(scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'M', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'B',\n",
       "       'M', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'M',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'M', 'M', 'B',\n",
       "       'B', 'M', 'B', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'M',\n",
       "       'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M',\n",
       "       'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B',\n",
       "       'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'M', 'B', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M',\n",
       "       'B', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'M', 'B', 'B', 'M',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'B', 'M', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M',\n",
       "       'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'M', 'B',\n",
       "       'M', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'M', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M',\n",
       "       'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B',\n",
       "       'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M',\n",
       "       'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'M', 'M', 'B', 'B', 'B', 'M'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions on the data\n",
    "#predict function--> gives the predicted values\n",
    "# Syntax:objectname.predict(Input)\n",
    "y_train_pred = knn.predict(scaled_X_train)\n",
    "y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.93      1.00      0.96       259\n",
      "           M       1.00      0.85      0.92       139\n",
      "\n",
      "    accuracy                           0.95       398\n",
      "   macro avg       0.96      0.92      0.94       398\n",
      "weighted avg       0.95      0.95      0.95       398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the accuracy, classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9532163742690059,\n",
       " 0.9590643274853801,\n",
       " 0.9649122807017544,\n",
       " 0.9649122807017544,\n",
       " 0.9649122807017544,\n",
       " 0.9590643274853801,\n",
       " 0.9707602339181286,\n",
       " 0.9766081871345029,\n",
       " 0.9766081871345029,\n",
       " 0.9766081871345029,\n",
       " 0.9766081871345029,\n",
       " 0.9707602339181286,\n",
       " 0.9707602339181286,\n",
       " 0.9707602339181286,\n",
       " 0.9707602339181286,\n",
       " 0.9649122807017544,\n",
       " 0.9649122807017544,\n",
       " 0.9649122807017544,\n",
       " 0.9649122807017544]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Checking for optimum k-value\n",
    "# Build the models with multiple k values\n",
    "scores=[]\n",
    "for k in range(1, 20):\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_model.fit(scaled_X_train, y_train)\n",
    "    pred_test = knn_model.predict(scaled_X_test)\n",
    "    scores.append(accuracy_score(y_test, pred_test))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x474b240288>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of K values and Scores\n",
    "plt.plot(range(1,20), scores, marker='o', markerfacecolor='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimum k value is 7\n",
    "final_model = KNeighborsClassifier(n_neighbors=7, metric='euclidean')\n",
    "final_model.fit(scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'M', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B',\n",
       "       'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'B',\n",
       "       'M', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'M',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'M', 'M', 'B',\n",
       "       'B', 'M', 'B', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'M',\n",
       "       'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M',\n",
       "       'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'B', 'B',\n",
       "       'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B',\n",
       "       'M', 'M', 'B', 'M', 'M', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'M',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'M', 'B', 'B', 'M',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'M', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'M', 'B', 'M', 'M', 'B',\n",
       "       'B', 'B', 'M', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'M',\n",
       "       'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'M', 'B',\n",
       "       'M', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M',\n",
       "       'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B',\n",
       "       'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M',\n",
       "       'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'M', 'M', 'B', 'M', 'B', 'M'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction on  training data\n",
    "final_train_pred = final_model.predict(scaled_X_train)\n",
    "final_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x474b2694c8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD4CAYAAADSIzzWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAASZklEQVR4nO3deZCdVZnH8e+TsCdsMRDJIptBB1yAQlSQGRSVxYVVBUfIUGioGiLggqKWoiOUzMgmotQE2axBFgeQSAEKkQFFVgVDSFjCIoSEhG1CEAbovs/80Zd4Ezq3b6dv9+n75vuhTvW9577L6aquXx7Oe973RmYiSRp6I0oPQJJWVwawJBViAEtSIQawJBViAEtSIWsM9glee+YRl1noDdYdv1vpIWgY6nr1yRjoMfqTOWuO3WrA5xsIK2BJKmTQK2BJGlK17tIjaJkVsKRq6e5qvTUREZMi4saImBsR90XEMfX+70bEkxFxT73t07DPNyJiXkQ8EBF79jVUK2BJlZJZa9ehuoCvZOafI2J94E8RcX39s9Mz85TGjSNiW+BgYDtgPHBDRGyTmSstyQ1gSdVSa08AZ+ZCYGH99dKImAtMaLLLvsAlmfkK8GhEzAN2Bm5d2Q5OQUiqlqy13CJiakTc1dCm9nbIiNgC2AG4vd41LSJmRcR5EbFxvW8C8ETDbvNpHtgGsKSKqXW33DJzembu1NCmr3i4iBgNXA4cm5kvAGcDWwPb01Mhn/r6pr2MpumSOKcgJFVL++aAiYg16QnfizLzCoDMXNTw+TnA1fW384FJDbtPBBY0O74VsKRKye6ullszERHAucDczDytoX+zhs32B2bXX88ADo6ItSNiS2AycEezc1gBS6qWNl2EA3YFDgXujYh76n3fBA6JiO3pmV54DDgSIDPvi4jLgDn0rKA4qtkKCDCAJVVNm6YgMvMP9D6ve02TfU4CTmr1HAawpGrpoDvhDGBJ1dLGi3CDzQCWVC19XFwbTgxgSdXSvotwg84AllQpfSw8GFYMYEnV4hywJBXiFIQkFWIFLEmFdL9WegQtM4AlVYtTEJJUiFMQklSIFbAkFWIAS1IZ6UU4SSrEOWBJKsQpCEkqxApYkgqxApakQqyAJamQLh/ILkllWAFLUiHOAUtSIVbAklSIFbAkFWIFLEmFuApCkgrJLD2ClhnAkqrFOWBJKsQAlqRCvAgnSYV0d5ceQcsMYEnV4hSEJBViAEtSIR00Bzyi9AAkqZ2yli23ZiJiUkTcGBFzI+K+iDim3j8mIq6PiIfqPzeu90dEnBkR8yJiVkTs2NdYDWBJ1VKrtd6a6wK+kpn/ALwPOCoitgWOB2Zm5mRgZv09wN7A5HqbCpzd1wkMYEnV0t3demsiMxdm5p/rr5cCc4EJwL7AhfXNLgT2q7/eF/h59rgN2CgiNmt2DgNYUrX0owKOiKkRcVdDm9rbISNiC2AH4HZgXGYuhJ6QBjatbzYBeKJht/n1vpXyIpykaunHKojMnA5Mb7ZNRIwGLgeOzcwXImKlm/Z2imbHtgKWVC2Zrbc+RMSa9ITvRZl5Rb170etTC/Wfi+v984FJDbtPBBY0O74BLKla2nQRLnpK3XOBuZl5WsNHM4Ap9ddTgKsa+g+rr4Z4H7Dk9amKlelzCiIi3k7P5PIEesrpBcCMzJzb176SNOT6WF7WD7sChwL3RsQ99b5vAicDl0XEEcDjwKfqn10D7APMA14CDu/rBE0DOCK+DhwCXALcUe+eCFwcEZdk5sn9+nUkabC16VkQmfkHep/XBdijl+0TOKo/5+irAj4C2C4zX2vsjIjTgPvo+ZfgDepXEqcC/PTUE/n8YYf0Z0yStMqyQrci14DxwF9X6N+s/lmvGq8svvbMI53zePqVWLjoab75/VN45rnnGRHBQfvuzaGf3o+fnPtfXD7jOjbeaEMAjjlyCv+4y85c/Zvfcf4vLl+2/4MPP8ovz/sxb99m61K/goaBiRPHc8F5P2LcmzehVqvxs59dxI/POrf0sKqnfVMQg66vAD4WmBkRD/H39W1vAd4KTBvMgQ0na4wcyXFf/ALbvu2t/O1vL/HpI45ml/fsAMChn9mPwz970HLbf3zPD/HxPT8E9ITv0cf/m+Erurq6OO5r3+Pue2YzevQo7rj9Om6YeTNz5z5UemjV0kHPgmgawJl5XURsA+xMz0W4oGepxZ2Z2TkP3RygTcaOYZOxYwAYNWo9ttp8Eouefralfa+5/ib2/vA/Debw1CGeemoxTz3Vs2LpxRf/xv33P8SE8W82gNutQhUwmVkDbhuCsXSEJxcuYu5DD/Ou7d7G3ffO4eLLf82M62ay3dsnc9y0L7DhBusvt/11M2/ix/9+QqHRarjafPOJbP/ud3D7HXeXHkr1dHVObeg64H546aWX+dK3TuTrRx/J6FGj+Mz+H+Pay87j8gt+wiZvGsMPzzpnue1n3Xc/666zDpO32qLMgDUsjRq1Hpddeg5f/uoJLF36YunhVE/WWm+FGcAteq2ri2O/dSIf++gH+cjuuwIwdszGjBw5khEjRnDQJ/dm9pwHl9vn2hucftDy1lhjDX556TlcfPGV/OpX15YeTjXVsvVWmAHcgszkOz84g602n8SUgw9Y1v/0M88tez3zpj/y1q02X/a+Vqvx2xt/bwBrOedMP5W598/jjB81ffyABiBrtZZbaT6MpwV3z7qPX183k8lbb8GBU3rWWR9z5BSuueEmHnjoEQiY8OZxnPC1o5ftc9c9sxm3yVgmTWj6NDqtRnbd5T0c+rmDmHXvHO6687cAfPvbJ3Ptdb8rPLKKGQaVbasiW3ggxUBUYR2w2m/d8buVHoKGoa5Xn1zpo8Za9eJx+7ecOaN/eOWAzzcQVsCSqsWvpZekMvr6rrfhxACWVC0GsCQVMgxWN7TKAJZULVbAklSIASxJZWS3UxCSVIYVsCSV4TI0SSrFAJakQjpnCtgAllQt2dU5CWwAS6qWzslfA1hStXgRTpJKsQKWpDKsgCWpFCtgSSoju0qPoHUGsKRKGQbfNt8yA1hStRjAklSGFbAkFWIAS1Ih2V30m+b7ZUTpAUhSO2Wt9daXiDgvIhZHxOyGvu9GxJMRcU+97dPw2TciYl5EPBARe/Z1fCtgSZWStbZWwBcAZwE/X6H/9Mw8pbEjIrYFDga2A8YDN0TENpnZvbKDWwFLqpR2VsCZeTPwXIun3he4JDNfycxHgXnAzs12MIAlVUpmtNwGYFpEzKpPUWxc75sAPNGwzfx630oZwJIqpT8VcERMjYi7GtrUFk5xNrA1sD2wEDi13t9bojd9MIVzwJIqpdaPVRCZOR2Y3p/jZ+ai119HxDnA1fW384FJDZtOBBY0O5YVsKRKyVq03FZFRGzW8HZ/4PUVEjOAgyNi7YjYEpgM3NHsWFbAkiqlnasgIuJiYHdgbETMB04Ado+I7emZXngMOBIgM++LiMuAOUAXcFSzFRBgAEuqmGzj44Az85Beus9tsv1JwEmtHt8AllQpbV4HPKgMYEmVMsDlZUPKAJZUKd0d9CwIA1hSpVgBS1IhzgFLUiHtXAUx2AxgSZViBSxJhXTXOucGXwNYUqU4BSFJhdRcBSFJZbgMTZIKcQqiwdgtPjLYp1AHumXse0sPQRXlFIQkFeIqCEkqpINmIAxgSdXiFIQkFeIqCEkqpFZ6AP1gAEuqlOz12+GHJwNYUqV0OQUhSWVYAUtSIc4BS1IhVsCSVIgVsCQV0m0FLElldNA3EhnAkqqlZgUsSWX4MB5JKsSLcJJUSC2cgpCkIrpLD6AfDGBJleIqCEkqxFUQklRIJ62C6Jxvr5OkFtSi9daXiDgvIhZHxOyGvjERcX1EPFT/uXG9PyLizIiYFxGzImLHvo5vAEuqlFo/WgsuAPZaoe94YGZmTgZm1t8D7A1MrrepwNl9HdwAllQp3dF660tm3gw8t0L3vsCF9dcXAvs19P88e9wGbBQRmzU7vgEsqVL6UwFHxNSIuKuhTW3hFOMycyFA/eem9f4JwBMN282v962UF+EkVUp/7oTLzOnA9Dadureauuk1QStgSZWS0XpbRYten1qo/1xc758PTGrYbiKwoNmBDGBJldLmi3C9mQFMqb+eAlzV0H9YfTXE+4Alr09VrIxTEJIqpZ23IkfExcDuwNiImA+cAJwMXBYRRwCPA5+qb34NsA8wD3gJOLyv4xvAkiqlnbciZ+YhK/loj162TeCo/hzfAJZUKT6OUpIKMYAlqZBOehaEASypUnwcpSQV4gPZJamQWgdNQhjAkirFi3CSVEjn1L8GsKSKsQKWpEK6onNqYANYUqV0TvwawJIqxikISSrEZWiSVEjnxK8BLKlinIKQpEK6O6gGNoAlVYoVsCQVklbAklSGFbAkFeIyNEkqpHPi1wCWVDFdHRTBBrCkSumki3AjVnXHiDi8yWdTI+KuiLjr1ddeWNVTSFK/1frRSlvlAAa+t7IPMnN6Zu6UmTutteYGAzjF8HfWT09m3qN3cOsd1y7r22//vbntzmt5/oWH2GGHdxYcnQbTlqcdxY6zzuedvztjWd+kbx/Gu24+k3fecBqTz/06IzdYD4BYYyRbnfFF3jnzdN5105mMn3ZAqWFXXvbjv9KaBnBEzFpJuxcYN0RjHNZ+cdHlHLjf8v8zMGfOg3zus//KLbfcUWhUGgrPXHoj9//z95fre+HmvzDrg8dy74e/zP89soDxXzwQgDGf2IURa6/JvXt8idl7fZVND/0oa03cpMSwK6+TKuC+5oDHAXsCz6/QH8AfB2VEHeaPt9zJW94yYbm+Bx94uNBoNJSW3j7nDSG65Ka/LHv94p8eZMzH39/zJpMR660NI0cwYp21qL3aRfeLLw/lcFcb3Vm+sm1VXwF8NTA6M+9Z8YOI+J9BGZFUEZsc8iGeveoWAJ67+lY23nNndrznXEasuzZ/PeF8uv/3xcIjrKbKrAPOzCOafPbZ9g9HqobxRx9IdtV49oqbARi1w2Syu8bdO3yekRuOZttfncgLv5/FK48vKjzS6hkOc7utGshFOEm9GPup3dnowzvx8LTT/963/24sufFusqubrmeXsPTO+xn17q0LjrK6OmkO2ACW2mjD3Xdg/FH78+C//IDay68u63/lyWfY4AM9K2JGrLs26++4DS/Pe7LUMCutRrbcSosc5AnrDUdvXf63HETnnn8GH9jtvbzpTRuzePEz/OCkH/H880v4j1O+w9ixY1iyZCn3zprDAfutdNn0aum3G7y79BAGbOuffokN3v8O1hizPl1PL2H+qZcwftoBxNpr0vX8UqDnQtxjx/8nI9Zbh61On8a620wkInj60t+x8OyrCv8Gw897F1wRAz3GQZt/suXM+e+/zhjw+QbCAFYRVQhgtV87Anj/t3yi5cy58vFfFw1gb0WWVCnDYWqhVQawpEpp58W1iHgMWAp0A12ZuVNEjAEuBbYAHgM+nZkr3ivREi/CSaqUQbgV+YOZuX1m7lR/fzwwMzMnAzPr71eJASypUoZgFcS+wIX11xcC+63qgQxgSZWSmS23xic31tvUFQ8H/DYi/tTw2bjMXFg/10Jg01Udq3PAkiqlP19Ln5nTgelNNtk1MxdExKbA9RFx/0DH18gKWFKltHMKIjMX1H8uBq4EdgYWRcRmAPWfi1d1rAawpErpzxREMxExKiLWf/018FFgNjADmFLfbAqwynfUOAUhqVLauA54HHBlREBPVv4iM6+LiDuByyLiCOBx4FOregIDWFKltOtpaJn5CPCGWzYz81lgj3acwwCWVClVeiC7JHUUb0WWpEIMYEkqZLCf8NhOBrCkSrEClqRCOuk74QxgSZXSncPh295aYwBLqhTngCWpEOeAJakQ54AlqZCaUxCSVIYVsCQV4ioISSrEKQhJKsQpCEkqxApYkgqxApakQrqzu/QQWmYAS6oUb0WWpEK8FVmSCrEClqRCXAUhSYW4CkKSCvFWZEkqxDlgSSrEOWBJKsQKWJIKcR2wJBViBSxJhbgKQpIK8SKcJBXiFIQkFeKdcJJUiBWwJBXSSXPA0Un/WnS6iJiamdNLj0PDi38Xq68RpQewmplaegAalvy7WE0ZwJJUiAEsSYUYwEPLeT71xr+L1ZQX4SSpECtgSSrEAJakQgzgIRIRe0XEAxExLyKOLz0elRcR50XE4oiYXXosKsMAHgIRMRL4CbA3sC1wSERsW3ZUGgYuAPYqPQiVYwAPjZ2BeZn5SGa+ClwC7Ft4TCosM28Gnis9DpVjAA+NCcATDe/n1/skrcYM4KERvfS5/k9azRnAQ2M+MKnh/URgQaGxSBomDOChcScwOSK2jIi1gIOBGYXHJKkwA3gIZGYXMA34DTAXuCwz7ys7KpUWERcDtwJvi4j5EXFE6TFpaHkrsiQVYgUsSYUYwJJUiAEsSYUYwJJUiAEsSYUYwJJUiAEsSYX8P9tsLZiOa/sLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix of Training data\n",
    "#Syntax: confusion_matrix(ActualValues, Predicted Values)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sns.heatmap(confusion_matrix(y_train, final_train_pred), annot=True, \n",
    "            fmt='d', annot_kws={'va':'top','ha':'right'}) # d--> integer formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.96      0.99      0.98       259\n",
      "           M       0.98      0.92      0.95       139\n",
      "\n",
      "    accuracy                           0.97       398\n",
      "   macro avg       0.97      0.96      0.96       398\n",
      "weighted avg       0.97      0.97      0.97       398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for training Data\n",
    "# Precision--> PPV--> Out of the positive predicted values, how many truely positive\n",
    "print(classification_report(y_train, final_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M',\n",
       "       'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'M', 'M', 'B',\n",
       "       'B', 'M', 'M', 'M', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'M', 'M', 'M', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'M',\n",
       "       'B', 'M', 'B', 'B', 'M', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'M',\n",
       "       'M', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'M', 'B', 'M', 'B',\n",
       "       'B', 'M', 'M', 'M', 'M', 'B', 'M', 'M', 'M', 'B', 'B', 'M', 'M',\n",
       "       'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'M',\n",
       "       'M', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B',\n",
       "       'M', 'M', 'M', 'M', 'B', 'M', 'M', 'M', 'M', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions on Test Data\n",
    "final_test_pred = final_model.predict(scaled_X_test)  # y_test\n",
    "final_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x474b39c688>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare actual values of test data(y_test) and final_test_pred(model predicted values)\n",
    "# Confusion_matrix(actualValues, predictedValues)\n",
    "sns.heatmap(confusion_matrix(y_test, final_test_pred), annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.96      0.99      0.97        98\n",
      "           M       0.99      0.95      0.97        73\n",
      "\n",
      "    accuracy                           0.97       171\n",
      "   macro avg       0.97      0.97      0.97       171\n",
      "weighted avg       0.97      0.97      0.97       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report for Test Data\n",
    "print(classification_report(y_test, final_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What is the accuracy we can get with our data random_state=2, 80%, random_state=5, 82%, random_state= 6, 76%\n",
    "\n",
    "\n",
    "##### Whenever we keep changing our random state, accuracy fluctuates. In order to overcome this problem we use KFold Cross Validation\n",
    "\n",
    "\n",
    "##### When we use KFold Cross Validation--> Our model will be trained on all the records considering all the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
